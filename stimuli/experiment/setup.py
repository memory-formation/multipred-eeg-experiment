import datetime
import json
import logging
import random
from pathlib import Path

from experiment.eyelinker import EyeLinker

from psychos import Window
from psychos.gui import Dialog

from .constants import BACKGROUND_COLOR, DATA_FOLDER, PHASES, SCREENS


def generate_localizer_sequences(block_modality="visual", target_modality="visual"):
    """
    Generate a list of 8 stimuli for trials of the localizer phase.
    A sequence for each modality.
    The visual stimuli are Gabor patches with orientations 0, 45, 90, and 135 degrees.
    The auditory stimuli are sine waves at frequencies 100Hz, 160Hz, 1000Hz and 1600Hz.
    """

    trials = []
    for trial in range(PHASES["localizer_trials"]):
        stimuli = [(45, 100), (45, 160), (135, 100), (135, 160)] * 2 # define multimodal pairs to ensure balanced presentation
        random.shuffle(stimuli) # shuffle the pairs
        visual_stimuli = [stim[0] for stim in stimuli] # extract the visual stimuli
        auditory_stimuli = [stim[1] for stim in stimuli] # extract the auditory stimuli

        target_sequence = [0] * len(visual_stimuli) # create a sequence of zeros and randomly add ones to mark targets

        p = random.random()
        if p < 0.5:
            target_count = 0  # No targets
        elif p < 0.85:
            # One target
            idx = random.randint(0, len(target_sequence) - 1)
            target_sequence[idx] = 1
            target_count = 1
        else:
            # Multiple targets (2 or 3)
            target_count = random.choice([2, 3])
            indices = random.sample(range(len(target_sequence)), target_count)
            for idx in indices:
                target_sequence[idx] = 1


        # Create a trial with the randomized stimuli
        trial_data = {
            "visual_sequence": visual_stimuli,
            "auditory_sequence": auditory_stimuli,
            "target_sequence": target_sequence,
            "target_count": target_count,
            "block_modality": [block_modality] * len(visual_stimuli),
            "target_modality": [target_modality] * len(visual_stimuli),
        }

        trials.append(trial_data)
    return trials



def generate_trials(auditory_mapping=0, visual_mapping=0):
    """
    Generates lists of trials for each block of the learning and test phases.
    
    In the visual modality, there are two predictive cues (vertical, horizontal) and one neutral stimulus (neutralV).
    The probabilities are as follows (with weights shown in parentheses):
    
      - Under one mapping (Condition A):
          * Horizontal: EXPicted outcome is 45 (weight 3) and UEXicted outcome is 135 (weight 1)
          * Vertical:   EXPicted outcome is 135 (weight 3) and UEXicted outcome is 45 (weight 1)
      - Under the alternate mapping (Condition B):
          * Horizontal: EXPicted outcome is 135 (weight 3) and UEXicted outcome is 45 (weight 1)
          * Vertical:   EXPicted outcome is 45 (weight 3) and UEXicted outcome is 135 (weight 1)
    
    The neutral condition is always balanced:
      - neutralV -> 45 (weight 1) and neutralV -> 135 (weight 1).
    
    The auditory modality is structured analogously, with two predictive tones (1000Hz, 1600Hz) and one neutral tone (neutralA)
    that will be followed by either 100Hz or 160Hz.
    
    Trials are generated by taking the full crossâ€“product of visual and auditory pairs.
    Each unique visualâ€“auditory combination is repeated a number of times equal to the product
    of the visual weight and the auditory weight. 
    
    Parameters:
        auditory_mapping (int): 0 or 1, indicating the mapping condition for auditory stimuli.
        visual_mapping (int): 0 or 1, indicating the mapping condition for visual stimuli.
    
    Returns:
       list of dictionaries for each trial, including the leading and trailing stimuli, their conditions, and the target status.
    """

    
    # Randomize visual mapping: choose between two conditions.
    if visual_mapping == 0:
        # Condition A: horizontal->CW high, vertical->CCW high.
        visual_pairs = [
            # Vertical stimulus: high probability for CCW, low for CW.
            (90, 135, 'EXP', 3),
            (90, 45,  'UEX', 1),
            # Horizontal stimulus: high probability for CW, low for CCW.
            (0, 45, 'EXP', 3),
            (0, 135, 'UEX', 1),
        ]
    else:
        # Condition B: horizontal->CCW high, vertical->CW high.
        visual_pairs = [
            # Vertical stimulus: high probability for CW, low for CCW.
            (90, 45, 'EXP', 3),
            (90, 135, 'UEX', 1),
            # Horizontal stimulus: high probability for CCW, low for CW.
            (0, 135, 'EXP', 3),
            (0, 45, 'UEX', 1),
        ]
    # Add balanced neutral visual pairs.
    visual_pairs.append(('neutralV', 45, 'neutral', 2))
    visual_pairs.append(('neutralV', 135, 'neutral', 2))
    
    # Randomize auditory mapping: choose between two conditions.
    if auditory_mapping == 0:
        # Condition A: 1000Hz->100Hz high, 1600Hz->160Hz high.
        auditory_pairs = [
            (1000, 100, 'EXP', 3),
            (1000, 160, 'UEX', 1),
            (1600, 160, 'EXP', 3),
            (1600, 100, 'UEX', 1),
        ]
    else:
        # Condition B: 1000Hz->160Hz high, 1600Hz->100Hz high.
        auditory_pairs = [
            (1000, 160, 'EXP', 3),
            (1000, 100, 'UEX', 1),
            (1600, 100, 'EXP', 3),
            (1600, 160, 'UEX', 1),
        ]
    # Add balanced neutral auditory pairs.
    auditory_pairs.append(('neutralA', 100, 'neutral', 0)) # 0 for no auditory neutral condition
    auditory_pairs.append(('neutralA', 160, 'neutral', 0))
    
    # Build the crossâ€“product.
    trials = []
    for v_lead, v_target, v_cond, v_weight in visual_pairs:
        for a_lead, a_target, a_cond, a_weight in auditory_pairs:
            count = v_weight * a_weight  # number of repetitions for this combination
            
            if count == 0:
                continue  # skip 

            if count % 2 == 0: # event count of trials for this combination 
                n_zeros = count // 2 # we can have an equal number of target and non-target trials
                n_ones = count // 2
            else: # odd number of trials, we need to randomize the distribution of targets and non-targets
                if random.choice([True, False]): # more non-targets than targets
                    n_zeros = count // 2
                    n_ones = count - n_zeros
                else: # more targets than non-targets
                    n_ones = count // 2
                    n_zeros = count - n_ones

            target_list = [0] * n_zeros + [1] * n_ones # create a list of zeros and ones and shuffle
            random.shuffle(target_list)

            for t in target_list:
                trial = {
                'v_leading': v_lead,
                'v_trailing': v_target,
                'v_pred': v_cond,
                'a_leading': a_lead,
                'a_trailing': a_target,
                'a_pred': a_cond,
                'target': t,
                'auditory_mapping': auditory_mapping,
                'visual_mapping': visual_mapping,
             }
                trials.append(trial)
    
    # Shuffle the trial order to randomize sequence.
    random.shuffle(trials)
    return trials

def generate_explicit_trials(block_modality="visual", visual_mapping=0, auditory_mapping=0):
    """
    Generates a list of trials for the explicit phase of the experiment.
    """

    # Randomize visual mapping: choose between two conditions.
    if visual_mapping == 0:
        # Condition A: horizontal->CW high, vertical->CCW high.
        visual_pairs = [
            (90, 135, 'EXP', 3), # asking 3 times for each pair
            (90, 45,  'UEX', 3),
            (0, 45, 'EXP', 3),
            (0, 135, 'UEX', 3),
        ]
    else:
        # Condition B: horizontal->CCW high, vertical->CW high.
        visual_pairs = [
            (90, 45, 'EXP', 3),
            (90, 135, 'UEX', 3),
            (0, 135, 'EXP', 3),
            (0, 45, 'UEX', 3),
        ]
    
    # Randomize auditory mapping: choose between two conditions.
    if auditory_mapping == 0:
        # Condition A: 1000Hz->100Hz high, 1600Hz->160Hz high.
        auditory_pairs = [
            (1000, 100, 'EXP', 3),
            (1000, 160, 'UEX', 3),
            (1600, 160, 'EXP', 3),
            (1600, 100, 'UEX', 3),
        ]
    else:
        # Condition B: 1000Hz->160Hz high, 1600Hz->100Hz high.
        auditory_pairs = [
            (1000, 160, 'EXP', 3),
            (1000, 100, 'UEX', 3),
            (1600, 100, 'EXP', 3),
            (1600, 160, 'UEX', 3),
        ]

    
    # Build list of trials
    trials = []

    if block_modality == "visual":
        # Visual modality
        for v_lead, v_target, v_cond, v_weight in visual_pairs:
            count = v_weight * 1
    

            for i in range(count):
                trial = {
                'modality': 'visual',
                'v_leading': v_lead,
                'v_trailing': v_target,
                'v_pred': v_cond,
                'a_leading': None,
                'a_trailing': None,
                'a_pred': None,
                'target': None,
                'auditory_mapping': auditory_mapping,
                'visual_mapping': visual_mapping,
             }
                trials.append(trial)
    else: 
        # Auditory modality
        for a_lead, a_target, a_cond, a_weight in auditory_pairs:
            count = a_weight * 1

            for i in range(count):
                trial = {
                'modality': 'auditory',
                'v_leading': None,
                'v_trailing': None,
                'v_pred': None,
                'a_leading': a_lead,
                'a_trailing': a_target,
                'a_pred': a_cond,
                'target': None,
                'auditory_mapping': auditory_mapping,
                'visual_mapping': visual_mapping,
             }
                trials.append(trial)
    
    # Shuffle the trial order to randomize sequence.
    random.shuffle(trials)
    return trials



def setup():

    data_folder = Path(DATA_FOLDER)
    data_folder.mkdir(exist_ok=True)  # Create data folder if it does not exist

    # ========= Initial dialog to check participant ID ==========
    dialog1 = Dialog(title="Participant Info")
    dialog1.add_field(name="participant", default="01", label="Participant ID", format=int)
    data = dialog1.show()
    if not data:
        raise RuntimeError("User cancelled the dialog.")

    participant_id = f"sub-{data['participant']:02d}"
    participant_folder = data_folder / participant_id
    participant_folder.mkdir(exist_ok=True)  # Create participant folder

    # ========= Set up logging ==========
    # Create a log file for the participant
    log_file = participant_folder / f"{participant_id}_triggers.log"

    # Set up root logger
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)

    # Clear existing handlers to avoid duplicate logs
    if logger.hasHandlers():
        logger.handlers.clear()

    # File handler
    file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    # ======= Create or load participant info ========
    #  Check if participant data already exists
    participant_info_path = participant_folder / f"{participant_id}_info.json"
    if not participant_info_path.exists():
        # Second dialog to collect demographic info
        dialog2 = Dialog(title="Demographic Information")
        dialog2.add_field(name="gender", default="female", label="Gender", choices=["female", "male", "other"])
        dialog2.add_field(name="age", default="18", label="Age", format=int)
        dialog2.add_field(name="handedness", default="right", label="Handedness", choices=["right", "left"])
        data = dialog2.show()
        if not data:
            raise RuntimeError("User cancelled the dialog.")

        # Store participant info
        participant_data = {
            "participant_id": participant_id,
            "date": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "gender": data["gender"],
            "age": data["age"],
            "handedness": data["handedness"],
        }

        # probabilistic associations mapping
        participant_data["auditory_mapping"] = random.choice([0, 1])
        participant_data["visual_mapping"] = random.choice([0, 1])

        # Key mappings
        learning_key_mapping1 = {"LEFT": "frequent", "RIGHT": "infrequent", "SPACE": "neutral"}
        learning_key_mapping2 = {"LEFT": "infrequent", "RIGHT": "frequent", "SPACE": "neutral"}

        test_key_mapping1 = {"LEFT": "deviant", "RIGHT": "normal"}
        test_key_mapping2 = {"LEFT": "normal", "RIGHT": "deviant"}

        explicit_key_mapping1 = {"LEFT": "frequent", "RIGHT": "infrequent"}
        explicit_key_mapping2 = {"LEFT": "infrequent", "RIGHT": "frequent"}


        # Localizer phase
        target_modalities = PHASES["localizer_targets"]
        random.shuffle(target_modalities)  # Randomize the order of the modalities
        for block, block_modality in enumerate(PHASES["localizer_blocks"]):
            if block_modality == "multimodal":
                target_modality = target_modalities[block] 
            else:
                target_modality = block_modality # if unimodal, necessarily the same as block modality

            participant_data[f"conditions_localizer_{block + 1}"] = generate_localizer_sequences(block_modality=block_modality, target_modality=target_modality)
        

        # Learning phase
        random_key_order = random.choice([True, False])
        for block in range(PHASES["learning_blocks"]):
            participant_data[f"conditions_learning_{block + 1}"] = generate_trials(participant_data["auditory_mapping"], participant_data["visual_mapping"])
            participant_data[f"keymapping_learning_{block + 1}"] = learning_key_mapping1 if block % 2 == random_key_order else learning_key_mapping2

        
        # Test phase
        random_key_order = random.choice([True, False])
        for block in range(PHASES["test_blocks"]):
            participant_data[f"conditions_test_{block + 1}"] = generate_trials(participant_data["auditory_mapping"], participant_data["visual_mapping"])
            participant_data[f"keymapping_test_{block + 1}"] = test_key_mapping1 if block % 2 == random_key_order else test_key_mapping2

        
        # Explicit phase
        explicit_blocks = ["visual", "auditory"]
        explicit_keymappings = [explicit_key_mapping1, explicit_key_mapping2]
        random.shuffle(explicit_blocks) # randomize the order of the blocks
        random.shuffle(explicit_keymappings) # randomize the order of the key mappings

        for block, block_modality, key_mapping in zip([1, 2], explicit_blocks, explicit_keymappings):
            participant_data[f"conditions_explicit_{block}"] = generate_explicit_trials(block_modality, participant_data["visual_mapping"], participant_data["auditory_mapping"])
            participant_data[f"keymapping_explicit_{block}"] = key_mapping


        # ðŸ”¹ Save JSON file
        with open(participant_info_path, "w") as f:
            json.dump(participant_data, f, indent=4)

    else:
        # Load participant data if the file exists
        with open(participant_info_path, "r") as f:
            participant_data = json.load(f)

    # Track completed blocks
    participant_data["completed_blocks"] = participant_data.get("completed_blocks", {
    "localizer": [],
    "learning": [],
    "test": [],
    "explicit": []
})
    # Check how many blocks have been completed
    completed_localizer = len(participant_data["completed_blocks"]["localizer"])
    completed_learning = len(participant_data["completed_blocks"]["learning"])
    completed_test = len(participant_data["completed_blocks"]["test"])
    completed_explicit = len(participant_data["completed_blocks"]["explicit"])
    

    # Dialog to select block and phase based on progress
    dialog3 = Dialog(title="Block Selection Based on Participant Progress")
    if completed_localizer == 0: # < len(PHASES["localizer_blocks"]):
        dialog3.add_field(name="phase", default="localizer", label="Phase", choices=["localizer", "learning", "test", "explicit"])
        dialog3.add_field(name="block", default=str(completed_localizer + 1), label="Block", format=int)
    elif completed_learning < PHASES["learning_blocks"]:
        dialog3.add_field(name="phase", default="learning", label="Phase", choices=["localizer", "learning", "test", "explicit"])
        dialog3.add_field(name="block", default=str(completed_learning + 1), label="Block", format=int)
    elif completed_test < PHASES["test_blocks"]:
        dialog3.add_field(name="phase", default="test", label="Phase", choices=["localizer", "learning", "test", "explicit"])
        dialog3.add_field(name="block", default=str(completed_test + 1), label="Block", format=int)
    elif completed_explicit < PHASES["explicit_blocks"]:
        dialog3.add_field(name="phase", default="explicit", label="Phase", choices=["localizer", "learning", "test", "explicit"])
        dialog3.add_field(name="block", default=str(completed_explicit + 1), label="Block", format=int)
    else:
        dialog3 = Dialog(title="All blocks completed. Running experiment again will overwrite data.")
        dialog3.add_field(name="phase", default="explicit", label="Phase", choices=["localizer", "learning", "test", "explicit"])
        dialog3.add_field(name="block", default=PHASES["explicit_blocks"], label="Block", format=int)

    dialog3.add_field(name="full_screen", default="Yes", label="Full screen", choices=["Yes", "No"])
    dialog3.add_field(name="screen_info", default="hp_laptop", label="experiment_screen", choices=["hp_laptop", "VU_experiment"])
    data = dialog3.show()
    if not data:
        raise RuntimeError("User cancelled the dialog.")

    block = data["block"]
    phase = data["phase"]
    full_screen = data["full_screen"]
    screen_info = SCREENS[data["screen_info"]]

    #  window for the experiment
    window = Window(background_color=BACKGROUND_COLOR, fullscreen=full_screen == "Yes")

    # Create eye tracker object. Will attempt to default to MockEyeLinker if no tracker connected
    tracker = EyeLinker(window, f'{data_folder}/{participant_id}/{participant_id}_eye.edf', 'RIGHT') 
    # initialize
    tracker.init_tracker()
    # funtion test and calibrate
    tracker.testFunAndCalib()

    return window, participant_data, phase, block, full_screen, screen_info, tracker


